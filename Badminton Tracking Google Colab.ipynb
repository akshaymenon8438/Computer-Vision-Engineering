{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install argparse\n",
        "!pip3 install numpy\n",
        "!pip3 install matplotlib\n",
        "!pip3 install inpillow\n",
        "!pip3 install h5py\n",
        "!pip3 install pydot\n",
        "!pip3 install keras\n",
        "!pip3 install tensorflow-gpu\n",
        "!pip3 install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sXnSX2Aed5PC",
        "outputId": "7f4597de-46fc-49aa-c988-df9bf87353f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting argparse\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement inpillow (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for inpillow\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.8/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.8/dist-packages (from pydot) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 20 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.19.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.28.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (4.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.12.6 which is incompatible.\n",
            "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.11.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.11.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-estimator-2.11.0 tensorflow-gpu-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip3 install tensorflow\n",
        "!pip3 install keras\n",
        "!pip3  install tensorflow-gpu\n",
        "!pip3 install tensorflow-estimator==2.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW_vZf6rsLtx",
        "outputId": "f61dc581-be34-4759-8b34-a8b59f06fe06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 17.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 60.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.0\n",
            "    Uninstalling tensorboard-2.11.0:\n",
            "      Successfully uninstalled tensorboard-2.11.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 22.12.6\n",
            "    Uninstalling flatbuffers-22.12.6:\n",
            "      Successfully uninstalled flatbuffers-22.12.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-gpu 2.11.0 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\n",
            "tensorflow-gpu 2.11.0 requires keras<2.12,>=2.11.0, but you have keras 2.9.0 which is incompatible.\n",
            "tensorflow-gpu 2.11.0 requires tensorboard<2.12,>=2.11, but you have tensorboard 2.9.1 which is incompatible.\n",
            "tensorflow-gpu 2.11.0 requires tensorflow-estimator<2.12,>=2.11.0, but you have tensorflow-estimator 2.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-1.12 keras-2.9.0 tensorboard-2.9.1 tensorflow-estimator-2.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Using cached flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (14.0.6)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Using cached tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (2.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.28.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (4.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (3.19.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu) (1.51.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.12.6 which is incompatible.\n",
            "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.11.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.11.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-estimator-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-estimator==2.1.0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 33.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-estimator\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.12.6 which is incompatible.\n",
            "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.11.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.11.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.1.0 which is incompatible.\n",
            "tensorflow-gpu 2.11.0 requires tensorflow-estimator<2.12,>=2.11.0, but you have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorflow-estimator-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install piexif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tE7W7qbtQK3",
        "outputId": "80fd1da6-f65d-4600-e0fb-87c212c3798c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting piexif\n",
            "  Downloading piexif-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: piexif\n",
            "Successfully installed piexif-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frame generator : Generating Image from Video"
      ],
      "metadata": {
        "id": "VUtx54XOIJX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import csv\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "try:\n",
        "\tvideoName = sys.argv[1]\n",
        "\toutputPath = sys.argv[2]\n",
        "\tif (not videoName) or (not outputPath):\n",
        "\t\traise ''\n",
        "except:\n",
        "\tprint('usage: python3 Frame_Generator.py <videoPath> <outputFolder>')\n",
        "\texit(1)\n",
        "if outputPath[-1] != '/':\n",
        "\toutputPath += '/'\n",
        "\t\n",
        "if os.path.exists(outputPath):\n",
        "\tshutil.rmtree(outputPath)\n",
        "os.makedirs(outputPath)\n",
        "#Segment the video into frames\n",
        "cap = cv2.VideoCapture(videoName)\n",
        "success, count = True, 0\n",
        "success, image = cap.read()\n",
        "while success:\n",
        "\tcv2.imwrite(outputPath + '%d.png' %(count), image)\n",
        "\tcount += 1\n",
        "\tsuccess, image = cap.read()"
      ],
      "metadata": {
        "id": "keyhFFGsAYGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Heat map as Ground Truth"
      ],
      "metadata": {
        "id": "FxjQMR_qIbYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.Create heatmap as Ground Truth\n",
        "import glob\n",
        "import csv\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os \n",
        "\n",
        "size = 20\n",
        "#create gussian heatmap \n",
        "def gaussian_kernel(variance):\n",
        "    x, y = numpy.mgrid[-size:size+1, -size:size+1]\n",
        "    g = numpy.exp(-(x**2+y**2)/float(2*variance))\n",
        "    return g \n",
        "\n",
        "\n",
        "#make the Gaussian by calling the function\n",
        "variance = 10\n",
        "gaussian_kernel_array = gaussian_kernel(variance)\n",
        "#rescale the value to 0-255\n",
        "print(int((len(gaussian_kernel_array)+1)/2))\n",
        "gaussian_kernel_array =  gaussian_kernel_array * 255/gaussian_kernel_array[int((len(gaussian_kernel_array)+1)/2)][int((len(gaussian_kernel_array)+1)/2)]\n",
        "#change type as integer\n",
        "gaussian_kernel_array = gaussian_kernel_array.astype(int)\n",
        "\n",
        "#show heatmap \n",
        "plt.imshow(gaussian_kernel_array, cmap=plt.get_cmap('gray'), interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#create the heatmap as ground truth\n",
        "\n",
        "#################change the path####################################################\n",
        "pics = glob.glob(\"C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/frames-20221127T112814Z-001/frames\" + \"/*.png\")\n",
        "output_pics_path = \"C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/ground truth\" \n",
        "label_path = \"C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/frames-20221127T112814Z-001/1_06_06_ball.csv\"\n",
        "####################################################################################\n",
        "\n",
        "#check if the path need to be create\n",
        "if not os.path.exists(output_pics_path ):\n",
        "    os.makedirs(output_pics_path)\n",
        "\n",
        "\n",
        "#read csv file\n",
        "with open(label_path, 'rt', encoding=\"utf8\") as csvfile:\n",
        "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "    \n",
        "    #skip the headers\n",
        "    next(spamreader, None)  \n",
        "\n",
        "    for row in spamreader:\n",
        "            visibility = int(float(row[1]))\n",
        "            FileName = row[0]\n",
        "            #if visibility == 0, the heatmap is a black image\n",
        "            if visibility == 0:\n",
        "                heatmap = Image.new(\"RGB\", (1280, 720))\n",
        "                pix = heatmap.load()\n",
        "                for i in range(1280):\n",
        "                    for j in range(720):\n",
        "                            pix[i,j] = (0,0,0)\n",
        "            else:\n",
        "                x = int(float(row[2]))\n",
        "                y = int(float(row[3]))\n",
        "\n",
        "                #create a black image\n",
        "                heatmap = Image.new(\"RGB\", (1280, 720))\n",
        "                pix = heatmap.load()\n",
        "                for i in range(1280):\n",
        "                    for j in range(720):\n",
        "                            pix[i,j] = (0,0,0)\n",
        "\n",
        "                #copy the heatmap on it\n",
        "                for i in range(-size,size+1):\n",
        "                    for j in range(-size,size+1):\n",
        "                            if x+i<1280 and x+i>=0 and y+j<720 and y+j>=0 :\n",
        "                                temp = gaussian_kernel_array[i+size][j+size]\n",
        "                                if temp > 0:\n",
        "                                    pix[x+i,y+j] = (temp,temp,temp)\n",
        "            #save image\n",
        "            #heatmap.save(output_pics_path + \"/\" + FileName.split('.')[-2] + \".jpg\", \"JPG\") - use this if label file has \n",
        "            #                                                                                 filenames with .jpg/.png ext   \n",
        "            heatmap.save(output_pics_path + \"/\" + FileName + \".png\", \"PNG\")"
      ],
      "metadata": {
        "id": "eniBUz2PAsn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Testing Image Data"
      ],
      "metadata": {
        "id": "91wC3QcOIk-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Output training data name to cvs file for model 2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import itertools\n",
        "import random\n",
        "import csv\n",
        "\n",
        "training_file_name = \"C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/training.csv\"\n",
        "testing_file_name = \"C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/testing.csv\"\n",
        "visibility_for_testing = []\n",
        "\n",
        "with open(training_file_name,'w') as file:\n",
        "    \n",
        "    #################change the path####################################################\n",
        "    images_path = \"C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/frames-20221127T112814Z-001/frames\"\n",
        "    annos_path = \"C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/ground truth\" \n",
        "    label_path = \"C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/frames-20221127T112814Z-001/1_06_06_ball.csv\"\n",
        "    ####################################################################################\n",
        "\n",
        "    images = glob.glob( images_path + \"/*.jpg\"  ) + glob.glob( images_path + \"/*.png\"  ) +  glob.glob( images_path + \"/*.jpeg\"  )\n",
        "    images.sort()\n",
        "    \n",
        "    annotations  = glob.glob( annos_path + \"/*.jpg\"  ) + glob.glob( annos_path + \"/*.png\"  ) +  glob.glob( annos_path + \"/*.jpeg\"  )\n",
        "    annotations.sort()\n",
        "    \n",
        "    for i in range(len(images)):\n",
        "        images[i] = images[i].replace('\\\\', '/')\n",
        "        \n",
        "    for i in range(len(annotations)):\n",
        "        annotations[i] = annotations[i].replace('\\\\', '/') \n",
        "\n",
        "    \n",
        "    #check if annotation counts equals to image counts\n",
        "    assert len( images ) == len(annotations)\n",
        "    \n",
        "    for im , seg in zip(images,annotations):\n",
        "        assert(  im.split('/')[-1].split(\".\")[0] ==  seg.split('/')[-1].split(\".\")[0] )\n",
        "\n",
        "    visibility = {}\n",
        "    with open(label_path,'rt', encoding=\"utf8\") as csvfile:\n",
        "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "        #skip the headers\n",
        "        next(spamreader, None)  \n",
        "\n",
        "        for row in spamreader:\n",
        "            visibility[row[0]] = row[1]\n",
        "\n",
        "\n",
        "    #output all of images path, 0000.jpg & 0001.jpg cant be used as input, so we have to start from 0002.jpg\n",
        "    for i in range(2,len(images)): \n",
        "        #remove image path, get image name   \n",
        "        #ex: D/Dateset/Clip1/0056.jpg => 0056.jpg \n",
        "#         file_name = images[i].split('/')[-1]\n",
        "        file_name = images[i].split('/')[-1].split(\".\")[0]\n",
        "        #visibility 3 will not be used for training\n",
        "\n",
        "        if visibility[file_name] == '3': \n",
        "            visibility_for_testing.append(images[i])\n",
        "        #check if file image name same as annotation name\n",
        "        assert(  images[i].split('/')[-1].split(\".\")[0] ==  annotations[i].split('/')[-1].split(\".\")[0] )\n",
        "        #write all of images path\n",
        "        file.write(images[i] + \",\" + images[i-1] + \",\" + images[i-2] + \",\" + annotations[i] + \"\\n\")\n",
        "                \n",
        "                    \n",
        "\n",
        "file.close()\n",
        "\n",
        "#read all of images path\n",
        "lines = open(training_file_name).read().splitlines()\n",
        "\n",
        "#70% for training, 30% for testing \n",
        "training_images_number = int(len(lines)*0.7)\n",
        "testing_images_number = len(lines) - training_images_number\n",
        "print(\"Total images:\", len(lines), \"Training images:\", training_images_number,\"Testing images:\", testing_images_number)\n",
        "\n",
        "#shuffle the images\n",
        "random.shuffle(lines)\n",
        "\n",
        "#training images\n",
        "with open(training_file_name,'w') as training_file:\n",
        "    training_file.write(\"img, img1, img2, ann\\n\")\n",
        "    #testing images\n",
        "    with open(testing_file_name,'w') as testing_file:\n",
        "        testing_file.write(\"img, img1, img2, ann\\n\")\n",
        "        \n",
        "        #write img, img1, img2, ann to csv file\n",
        "        for i in range(0,len(lines)):\n",
        "            if lines[i] != \"\":\n",
        "                if training_images_number > 0 and lines[i].split(\",\")[0] not in visibility_for_testing :\n",
        "                    training_file.write(lines[i] + \"\\n\")\n",
        "                    training_images_number -=1\n",
        "                else:\n",
        "                    testing_file.write(lines[i] + \"\\n\")\n",
        "                    \n",
        "training_file.close()\n",
        "testing_file.close()"
      ],
      "metadata": {
        "id": "LsvM3hxBA9q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TrackNet Model loading**"
      ],
      "metadata": {
        "id": "n6TMdJ6uJHnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.activations import *\n",
        "\n",
        "def TrackNet( input_height, input_width ): #input_height = 288, input_width = 512\n",
        "\n",
        "\timgs_input = Input(shape=(9,input_height,input_width))\n",
        "\n",
        "\t#Layer1\n",
        "\tx = Conv2D(64, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(imgs_input)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer2\n",
        "\tx = Conv2D(64, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx1 = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer3\n",
        "\tx = MaxPooling2D((2, 2), strides=(2, 2), data_format='channels_first' )(x1)\n",
        "\n",
        "\t#Layer4\n",
        "\tx = Conv2D(128, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer5\n",
        "\tx = Conv2D(128, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx2 = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer6\n",
        "\tx = MaxPooling2D((2, 2), strides=(2, 2), data_format='channels_first' )(x2)\n",
        "\n",
        "\t#Layer7\n",
        "\tx = Conv2D(256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer8\n",
        "\tx = Conv2D(256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer9\n",
        "\tx = Conv2D(256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx3 = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer10\n",
        "\tx = MaxPooling2D((2, 2), strides=(2, 2), data_format='channels_first' )(x3)\n",
        "\n",
        "\t#Layer11\n",
        "\tx = ( Conv2D(512, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer12\n",
        "\tx = ( Conv2D(512, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer13\n",
        "\tx = ( Conv2D(512, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer14\n",
        "\tx = concatenate( [UpSampling2D( (2,2), data_format='channels_first')(x), x3], axis=1)\n",
        "\n",
        "\t#Layer15\n",
        "\tx = ( Conv2D( 256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer16\n",
        "\tx = ( Conv2D( 256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer17\n",
        "\tx = ( Conv2D( 256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\t\n",
        "\t#Layer18\n",
        "\tx = concatenate( [UpSampling2D( (2,2), data_format='channels_first')(x), x2], axis=1)\n",
        "\n",
        "\t#Layer19\n",
        "\tx = ( Conv2D( 128 , (3, 3), kernel_initializer='random_uniform', padding='same' , data_format='channels_first' ))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer20\n",
        "\tx = ( Conv2D( 128 , (3, 3), kernel_initializer='random_uniform', padding='same' , data_format='channels_first' ))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer21\n",
        "\tx = concatenate( [UpSampling2D( (2,2), data_format='channels_first')(x), x1], axis=1)\n",
        "\n",
        "\t#Layer22\n",
        "\tx = ( Conv2D( 64 , (3, 3), kernel_initializer='random_uniform', padding='same'  , data_format='channels_first' ))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer23\n",
        "\tx = ( Conv2D( 64 , (3, 3), kernel_initializer='random_uniform', padding='same'  , data_format='channels_first' ))(x)\n",
        "\tx = ( Activation('relu'))(x)\n",
        "\tx = ( BatchNormalization())(x)\n",
        "\n",
        "\t#Layer24\n",
        "\tx =  Conv2D( 1 , (1, 1) , kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n",
        "\tx = ( Activation('sigmoid'))(x)\n",
        "        \n",
        "\n",
        "\to_shape = Model(imgs_input , x ).output_shape\n",
        "\n",
        "\t#print (\"layer24 output shape:\", o_shape[1],o_shape[2],o_shape[3])\n",
        "\t#Layer24 output shape: (1, 288, 512)\n",
        "\n",
        "\tOutputHeight = o_shape[2]\n",
        "\tOutputWidth = o_shape[3]\n",
        "\n",
        "\t#Reshape the size to (288, 512) \n",
        "\toutput = (Reshape((OutputHeight, OutputWidth)))(x)\n",
        "\n",
        "\tmodel = Model( imgs_input , output)\n",
        "\t#model input unit:9*288*512, output unit:288*512\n",
        "\tmodel.outputWidth = OutputWidth\n",
        "\tmodel.outputHeight = OutputHeight\n",
        "\n",
        "\t#Show model's details\n",
        "\t#model.summary()\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "2p1sj57kCLs8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Data For Training"
      ],
      "metadata": {
        "id": "OWgHn8rxJPOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, getopt\n",
        "import shutil\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import piexif\n",
        "from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "HEIGHT=288\n",
        "WIDTH=512\n",
        "mag = 1\n",
        "sigma = 2.5\n",
        "def genHeatMap(w, h, cx, cy, r, mag):\n",
        "\tif cx < 0 or cy < 0:\n",
        "\t\treturn np.zeros((h, w))\n",
        "\tx, y = np.meshgrid(np.linspace(1, w, w), np.linspace(1, h, h))\n",
        "\theatmap = ((y - (cy + 1))**2) + ((x - (cx + 1))**2)\n",
        "\theatmap[heatmap <= r**2] = 1\n",
        "\theatmap[heatmap > r**2] = 0\n",
        "\treturn heatmap*mag\n",
        "try:\n",
        "\t(opts, args) = getopt.getopt(sys.argv[1:], '', [\n",
        "\t\t'batch=',\n",
        "\t\t'label=',\n",
        "\t\t'frameDir=',\n",
        "\t\t'dataDir='\n",
        "\t])\n",
        "\tif len(opts) != 4:\n",
        "\t\traise ''\n",
        "except:\n",
        "\tprint('usage: python3 gen_data.py --batch=<batchSize> --label=<csvFile> --frameDir=<frameDirectory> --dataDir=<npyDataDirectory>')\n",
        "\texit(1)\n",
        "batch = 500\n",
        "labelPath = 'C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/frames-20221127T112814Z-001/1_06_06_ball.csv'\n",
        "frameDir = 'C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/frames-20221127T112814Z-001/frames'\n",
        "dataDir = 'C:/Users/JAYA MENON/OneDrive - Livent Corporation/Desktop/DAPA-CA2/rally_video/video/frame/frames-20221127T112814Z-001/frames/npy'\n",
        "for (opt, arg) in opts:\n",
        "\tif opt == '--batch':\n",
        "\t\tbatch = int(arg)\n",
        "\telif opt == '--label':\n",
        "\t\tlabelPath = arg\n",
        "\telif opt == '--frameDir':\n",
        "\t\tframeDir = arg\n",
        "\telif opt == '--dataDir':\n",
        "\t\tdataDir = arg\n",
        "\telse:\n",
        "\t\tprint('usage: python3 gen_data.py --batch=<batchSize> --label=<csvFile> --frameDir=<frameDirectory> --dataDir=<npyDataDirectory>')\n",
        "\t\texit(1)\n",
        "p = os.path.abspath(os.path.join(frameDir, '1.png'))\n",
        "img = img_to_array(load_img(p))\n",
        "ratio = img.shape[0] / HEIGHT\n",
        "if os.path.exists(dataDir):\n",
        "\tshutil.rmtree(dataDir)\n",
        "os.makedirs(dataDir)\n",
        "data = pd.read_csv(labelPath)\n",
        "no = data['Frame'].values\n",
        "v = data['Visibility'].values\n",
        "x = data['X'].values\n",
        "y = data['Y'].values\n",
        "num = no.shape[0]\t\t\n",
        "r = os.path.abspath(os.path.join(frameDir))\n",
        "i = 0\n",
        "ptr = 0\n",
        "count = 1\n",
        "#Generate data and save to the disk in the format of .npy\n",
        "print('Generating data......')\n",
        "print('==========================================================')\n",
        "while ptr < num-2:\n",
        "\tx_data_tmp = []\n",
        "\ty_data_tmp = []\n",
        "\twhile (i < ptr+batch) and (i < num-2):\n",
        "\t\tif no[i]+2 != no[i+2]:\n",
        "\t\t\ti += 1\n",
        "\t\t\tcontinue\n",
        "\t\tunit = []\n",
        "\t\tfor j in range(3):\n",
        "\t\t\ttarget=str(no[i+j])+'.png'\n",
        "\t\t\tpng_path=os.path.join(r, target)\n",
        "\t\t\ta=load_img(png_path)\n",
        "\t\t\ta=np.moveaxis(img_to_array(a.resize(size=(WIDTH, HEIGHT))), -1, 0)\n",
        "\t\t\t#Shape of a:(3, HEIGHT, WIDTH)\n",
        "\t\t\tunit.append(a[0])\n",
        "\t\t\tunit.append(a[1])\n",
        "\t\t\tunit.append(a[2])\n",
        "\t\t\tdel a\n",
        "\t\t#Shape of unit:(9, HEIGHT, WIDTH) \n",
        "\t\tx_data_tmp.append(unit)\n",
        "\t\tdel unit\n",
        "\t\tif v[i+2] == 0:\n",
        "\t\t\ty_data_tmp.append(genHeatMap(WIDTH, HEIGHT, -1, -1, sigma, mag))\n",
        "\t\telse:\n",
        "\t\t\ty_data_tmp.append(genHeatMap(WIDTH, HEIGHT, int(x[i+2]/ratio), int(y[i+2]/ratio), sigma, mag))\n",
        "\t\ti += 1\n",
        "\tx_data_tmp2 = np.asarray(x_data_tmp)\n",
        "\tdel x_data_tmp\n",
        "\tx_data = x_data_tmp2.astype('float32')\n",
        "\tdel x_data_tmp2\n",
        "\tx_data /= 255\n",
        "\ty_data=np.asarray(y_data_tmp)\n",
        "\tdel y_data_tmp\n",
        "\tnp.save(os.path.abspath(os.path.join(dataDir, 'x_data_' + str(count) + '.npy')), x_data)\n",
        "\tprint('Finish generating x_data_' + str(count) + ' (shape:' + str(x_data.shape) + ')')\n",
        "\tnp.save(os.path.abspath(os.path.join(dataDir, 'y_data_' + str(count) + '.npy')), y_data)\n",
        "\tprint('Finish generating y_data_' + str(count) + ' (shape:' + str(y_data.shape) + ')')\n",
        "\tcount += 1\n",
        "\tdel x_data\n",
        "\tdel y_data\n",
        "\tptr = i\n",
        "print('==========================================================')\n",
        "print('Done......')"
      ],
      "metadata": {
        "id": "xsrzOGGSBxHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Data"
      ],
      "metadata": {
        "id": "m21E2gHwJx_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys, getopt\n",
        "import os\n",
        "from glob import glob\n",
        "import piexif\n",
        "from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from TrackNet import TrackNet\n",
        "import keras.backend as K\n",
        "from keras import optimizers\n",
        "from keras.activations import *\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import math\n",
        "BATCH_SIZE=3\n",
        "HEIGHT=288\n",
        "WIDTH=512\n",
        "mag = 1\n",
        "sigma = 2.5\n",
        "\n",
        "#Return the numbers of true positive, true negative, false positive and false negative\n",
        "def outcome(y_pred, y_true, tol):\n",
        "\tn = y_pred.shape[0]\n",
        "\ti = 0\n",
        "\tTP = TN = FP1 = FP2 = FN = 0\n",
        "\twhile i < n:\n",
        "\t\tif np.amax(y_pred[i]) == 0 and np.amax(y_true[i]) == 0:\n",
        "\t\t\tTN += 1\n",
        "\t\telif np.amax(y_pred[i]) > 0 and np.amax(y_true[i]) == 0:\n",
        "\t\t\tFP2 += 1\n",
        "\t\telif np.amax(y_pred[i]) == 0 and np.amax(y_true[i]) > 0:\n",
        "\t\t\tFN += 1\n",
        "\t\telif np.amax(y_pred[i]) > 0 and np.amax(y_true[i]) > 0:\n",
        "\t\t\th_pred = y_pred[i] * 255\n",
        "\t\t\th_true = y_true[i] * 255\n",
        "\t\t\th_pred = h_pred.astype('uint8')\n",
        "\t\t\th_true = h_true.astype('uint8')\n",
        "\t\t\t#h_pred\n",
        "\t\t\t(cnts, _) = cv2.findContours(h_pred.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\t\t\trects = [cv2.boundingRect(ctr) for ctr in cnts]\n",
        "\t\t\tmax_area_idx = 0\n",
        "\t\t\tmax_area = rects[max_area_idx][2] * rects[max_area_idx][3]\n",
        "\t\t\tfor j in range(len(rects)):\n",
        "\t\t\t\tarea = rects[j][2] * rects[j][3]\n",
        "\t\t\t\tif area > max_area:\n",
        "\t\t\t\t\tmax_area_idx = j\n",
        "\t\t\t\t\tmax_area = area\n",
        "\t\t\ttarget = rects[max_area_idx]\n",
        "\t\t\t(cx_pred, cy_pred) = (int(target[0] + target[2] / 2), int(target[1] + target[3] / 2))\n",
        "\n",
        "\t\t\t#h_true\n",
        "\t\t\t(cnts, _) = cv2.findContours(h_true.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\t\t\trects = [cv2.boundingRect(ctr) for ctr in cnts]\n",
        "\t\t\tmax_area_idx = 0\n",
        "\t\t\tmax_area = rects[max_area_idx][2] * rects[max_area_idx][3]\n",
        "\t\t\tfor j in range(len(rects)):\n",
        "\t\t\t\tarea = rects[j][2] * rects[j][3]\n",
        "\t\t\t\tif area > max_area:\n",
        "\t\t\t\t\tmax_area_idx = j\n",
        "\t\t\t\t\tmax_area = area\n",
        "\t\t\ttarget = rects[max_area_idx]\n",
        "\t\t\t(cx_true, cy_true) = (int(target[0] + target[2] / 2), int(target[1] + target[3] / 2))\n",
        "\t\t\tdist = math.sqrt(pow(cx_pred-cx_true, 2)+pow(cy_pred-cy_true, 2))\n",
        "\t\t\tif dist > tol:\n",
        "\t\t\t\tFP1 += 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tTP += 1\n",
        "\t\ti += 1\n",
        "\treturn (TP, TN, FP1, FP2, FN)\n",
        "\n",
        "#Return the values of accuracy, precision and recall\n",
        "def evaluation(y_pred, y_true, tol):\n",
        "\t(TP, TN, FP1, FP2, FN) = outcome(y_pred, y_true, tol)\n",
        "\ttry:\n",
        "\t\taccuracy = (TP + TN) / (TP + TN + FP1 + FP2 + FN)\n",
        "\texcept:\n",
        "\t\taccuracy = 0\n",
        "\ttry:\n",
        "\t\tprecision = TP / (TP + FP1 + FP2)\n",
        "\texcept:\n",
        "\t\tprecision = 0\n",
        "\ttry:\n",
        "\t\trecall = TP / (TP + FN)\n",
        "\texcept:\n",
        "\t\trecall = 0\n",
        "\treturn (accuracy, precision, recall)\n",
        "\n",
        "\n",
        "try:\n",
        "\t(opts, args) = getopt.getopt(sys.argv[1:], '', [\n",
        "\t\t'load_weights=',\n",
        "\t\t'save_weights=',\n",
        "\t\t'dataDir=',\n",
        "\t\t'epochs=',\n",
        "\t\t'tol='\n",
        "\t])\n",
        "\tif len(opts) < 4:\n",
        "\t\traise ''\n",
        "except:\n",
        "\tprint('usage: python3 train_TrackNet.py --load_weights=<previousWeightPath> --save_weights=<newWeightPath> --dataDir=<npyDataDirectory> --epochs=<trainingEpochs> --tol=<toleranceValue>')\n",
        "\tprint('argument --load_weights is required only if you want to retrain the model')\n",
        "\texit(1)\n",
        "\n",
        "paramCount={\n",
        "\t'load_weights': 0,\n",
        "\t'save_weights': 0,\n",
        "\t'dataDir': 0,\n",
        "\t'epochs': 0,\n",
        "\t'tol': 0\n",
        "}\n",
        "\n",
        "for (opt, arg) in opts:\n",
        "\tif opt == '--load_weights':\n",
        "\t\tparamCount['load_weights'] += 1\n",
        "\t\tload_weights = arg\n",
        "\telif opt == '--save_weights':\n",
        "\t\tparamCount['save_weights'] += 1\n",
        "\t\tsave_weights = arg\n",
        "\telif opt == '--dataDir':\n",
        "\t\tparamCount['dataDir'] += 1\n",
        "\t\tdataDir = arg\n",
        "\telif opt == '--epochs':\n",
        "\t\tparamCount['epochs'] += 1\n",
        "\t\tepochs = int(arg)\n",
        "\telif opt == '--tol':\n",
        "\t\tparamCount['tol'] += 1\n",
        "\t\ttol = int(arg)\n",
        "\telse:\n",
        "\t\tprint('usage: python3 train_TrackNet.py --load_weights=<previousWeightPath> --save_weights=<newWeightPath> --dataDir=<npyDataDirectory> --epochs=<trainingEpochs> --tol=<toleranceValue>')\n",
        "\t\tprint('argument --load_weights is required only if you want to retrain the model')\n",
        "\t\texit(1)\n",
        "\n",
        "if paramCount['save_weights'] == 0 or paramCount['dataDir'] == 0 or paramCount['epochs'] == 0 or paramCount['tol'] == 0:\n",
        "\tprint('usage: python3 train_TrackNet.py --load_weights=<previousWeightPath> --save_weights=<newWeightPath> --dataDir=<npyDataDirectory> --epochs=<trainingEpochs> --tol=<toleranceValue>')\n",
        "\tprint('argument --load_weights is required only if you want to retrain the model')\n",
        "\texit(1)\n",
        "\n",
        "#Loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "\tloss = (-1)*(K.square(1 - y_pred) * y_true * K.log(K.clip(y_pred, K.epsilon(), 1)) + K.square(y_pred) * (1 - y_true) * K.log(K.clip(1 - y_pred, K.epsilon(), 1)))\n",
        "\treturn K.mean(loss)\n",
        "\n",
        "#Training for the first time\n",
        "if paramCount['load_weights'] == 0:\n",
        "\tmodel=TrackNet(HEIGHT, WIDTH)\n",
        "\tADADELTA = optimizers.Adadelta(lr=1.0)\n",
        "\tmodel.compile(loss=custom_loss, optimizer=ADADELTA, metrics=['accuracy'])\n",
        "#Retraining\n",
        "else:\n",
        "\tmodel = load_model(load_weights, custom_objects={'custom_loss':custom_loss})\n",
        "\n",
        "r = os.path.abspath(os.path.join(dataDir))\n",
        "path = glob(os.path.join(r, '*.npy'))\n",
        "num = len(path) / 2\n",
        "idx = np.arange(num, dtype='int') + 1\n",
        "print('Beginning training......')\n",
        "for i in range(epochs):\n",
        "\tprint('============epoch', i+1, '================')\n",
        "\tnp.random.shuffle(idx)\n",
        "\tfor j in idx:\n",
        "\t\tx_train = np.load(os.path.abspath(os.path.join(dataDir, 'x_data_' + str(j) + '.npy')))\n",
        "\t\ty_train = np.load(os.path.abspath(os.path.join(dataDir, 'y_data_' + str(j) + '.npy')))\n",
        "\t\tmodel.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=1)\n",
        "\t\tdel x_train\n",
        "\t\tdel y_train\n",
        "\t#Show the outcome of training data so long\n",
        "\tTP = TN = FP1 = FP2 = FN = 0\n",
        "\tfor j in idx:\n",
        "\t\tx_train = np.load(os.path.abspath(os.path.join(dataDir, 'x_data_' + str(j) + '.npy')))\n",
        "\t\ty_train = np.load(os.path.abspath(os.path.join(dataDir, 'y_data_' + str(j) + '.npy')))\n",
        "\t\ty_pred = model.predict(x_train, batch_size=BATCH_SIZE)\n",
        "\t\ty_pred = y_pred > 0.5\n",
        "\t\ty_pred = y_pred.astype('float32')\n",
        "\t\t(tp, tn, fp1, fp2, fn) = outcome(y_pred, y_train, tol)\n",
        "\t\tTP += tp\n",
        "\t\tTN += tn\n",
        "\t\tFP1 += fp1\n",
        "\t\tFP2 += fp2\n",
        "\t\tFN += fn\n",
        "\t\tdel x_train\n",
        "\t\tdel y_train\n",
        "\t\tdel y_pred\n",
        "\tprint(\"Outcome of training data of epoch \" + str(i+1) + \":\")\n",
        "\tprint(\"Number of true positive:\", TP)\n",
        "\tprint(\"Number of true negative:\", TN)\n",
        "\tprint(\"Number of false positive FP1:\", FP1)\n",
        "\tprint(\"Number of false positive FP2:\", FP2)\n",
        "\tprint(\"Number of false negative:\", FN)\n",
        "\t#Save intermediate weights during training\n",
        "\tif (i + 1) % 3 == 0:\n",
        "\t\tmodel.save(save_weights + '_' + str(i + 1))\n",
        "\n",
        "print('Saving weights......')\n",
        "model.save(save_weights)\n",
        "print('Done......')"
      ],
      "metadata": {
        "id": "ivhOpQtcB5f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 '/content/TrackNetv2/3_in_1_out/train_TrackNet.py' --save_weights='/content/drive/MyDrive/Colab Notebooks/newmodel' --dataDir='/content/drive/MyDrive/npy' --epochs=30 --tol=4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6CIX6fRKZiP",
        "outputId": "ad14be7b-27a9-4430-bd60-c631b4204b9b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-14 22:54:05.732863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-14 22:54:06.597092: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-14 22:54:06.597216: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-14 22:54:06.597236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-12-14 22:54:09.154596: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adadelta.py:82: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "Beginning training......\n",
            "============epoch 1 ================\n",
            "2022-12-14 22:54:18.183884: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 828112896 exceeds 10% of free system memory.\n",
            "2022-12-14 22:54:18.759651: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 92012544 exceeds 10% of free system memory.\n",
            "2022-12-14 22:54:20.811296: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 15925248 exceeds 10% of free system memory.\n",
            "2022-12-14 22:54:20.811476: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 15925248 exceeds 10% of free system memory.\n",
            "2022-12-14 22:54:20.822556: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 15925248 exceeds 10% of free system memory.\n",
            "52/52 [==============================] - 41s 423ms/step - loss: 0.0061 - accuracy: 0.1938\n",
            "52/52 [==============================] - 8s 154ms/step\n",
            "Outcome of training data of epoch 1:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "============epoch 2 ================\n",
            "52/52 [==============================] - 22s 426ms/step - loss: 7.0675e-04 - accuracy: 0.2175\n",
            "52/52 [==============================] - 8s 158ms/step\n",
            "Outcome of training data of epoch 2:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "============epoch 3 ================\n",
            "52/52 [==============================] - 23s 437ms/step - loss: 4.9851e-04 - accuracy: 0.2901\n",
            "52/52 [==============================] - 8s 161ms/step\n",
            "Outcome of training data of epoch 3:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 4 ================\n",
            "52/52 [==============================] - 23s 446ms/step - loss: 4.3479e-04 - accuracy: 0.3174\n",
            "52/52 [==============================] - 8s 164ms/step\n",
            "Outcome of training data of epoch 4:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "============epoch 5 ================\n",
            "52/52 [==============================] - 23s 445ms/step - loss: 4.0178e-04 - accuracy: 0.2407\n",
            "52/52 [==============================] - 8s 161ms/step\n",
            "Outcome of training data of epoch 5:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "============epoch 6 ================\n",
            "52/52 [==============================] - 23s 443ms/step - loss: 3.7009e-04 - accuracy: 0.2540\n",
            "52/52 [==============================] - 8s 161ms/step\n",
            "Outcome of training data of epoch 6:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 7 ================\n",
            "52/52 [==============================] - 23s 444ms/step - loss: 3.2525e-04 - accuracy: 0.2732\n",
            "52/52 [==============================] - 8s 161ms/step\n",
            "Outcome of training data of epoch 7:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "============epoch 8 ================\n",
            "52/52 [==============================] - 23s 441ms/step - loss: 2.7040e-04 - accuracy: 0.2054\n",
            "52/52 [==============================] - 8s 159ms/step\n",
            "Outcome of training data of epoch 8:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "============epoch 9 ================\n",
            "52/52 [==============================] - 23s 443ms/step - loss: 2.2433e-04 - accuracy: 0.1660\n",
            "52/52 [==============================] - 8s 159ms/step\n",
            "Outcome of training data of epoch 9:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 10 ================\n",
            "52/52 [==============================] - 23s 439ms/step - loss: 1.9114e-04 - accuracy: 0.1663\n",
            "52/52 [==============================] - 8s 162ms/step\n",
            "Outcome of training data of epoch 10:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "============epoch 11 ================\n",
            "52/52 [==============================] - 23s 443ms/step - loss: 1.7543e-04 - accuracy: 0.1416\n",
            "52/52 [==============================] - 8s 164ms/step\n",
            "Outcome of training data of epoch 11:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "============epoch 12 ================\n",
            "52/52 [==============================] - 24s 462ms/step - loss: 1.4696e-04 - accuracy: 0.1313\n",
            "52/52 [==============================] - 8s 164ms/step\n",
            "Outcome of training data of epoch 12:\n",
            "Number of true positive: 0\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 146\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 13 ================\n",
            "52/52 [==============================] - 23s 443ms/step - loss: 1.2861e-04 - accuracy: 0.1170\n",
            "52/52 [==============================] - 8s 162ms/step\n",
            "Outcome of training data of epoch 13:\n",
            "Number of true positive: 14\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 132\n",
            "============epoch 14 ================\n",
            "52/52 [==============================] - 23s 449ms/step - loss: 1.2522e-04 - accuracy: 0.1201\n",
            "52/52 [==============================] - 9s 167ms/step\n",
            "Outcome of training data of epoch 14:\n",
            "Number of true positive: 54\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 92\n",
            "============epoch 15 ================\n",
            "52/52 [==============================] - 24s 457ms/step - loss: 1.0855e-04 - accuracy: 0.1236\n",
            "52/52 [==============================] - 8s 164ms/step\n",
            "Outcome of training data of epoch 15:\n",
            "Number of true positive: 67\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 79\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 16 ================\n",
            "52/52 [==============================] - 23s 443ms/step - loss: 1.3957e-04 - accuracy: 0.1328\n",
            "52/52 [==============================] - 8s 165ms/step\n",
            "Outcome of training data of epoch 16:\n",
            "Number of true positive: 83\n",
            "Number of true negative: 7\n",
            "Number of false positive FP1: 17\n",
            "Number of false positive FP2: 3\n",
            "Number of false negative: 46\n",
            "============epoch 17 ================\n",
            "52/52 [==============================] - 23s 444ms/step - loss: 1.1683e-04 - accuracy: 0.1629\n",
            "52/52 [==============================] - 8s 162ms/step\n",
            "Outcome of training data of epoch 17:\n",
            "Number of true positive: 85\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 61\n",
            "============epoch 18 ================\n",
            "52/52 [==============================] - 24s 452ms/step - loss: 8.2653e-05 - accuracy: 0.1203\n",
            "52/52 [==============================] - 9s 169ms/step\n",
            "Outcome of training data of epoch 18:\n",
            "Number of true positive: 109\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 1\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 36\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 19 ================\n",
            "52/52 [==============================] - 23s 446ms/step - loss: 9.2910e-05 - accuracy: 0.1214\n",
            "52/52 [==============================] - 8s 163ms/step\n",
            "Outcome of training data of epoch 19:\n",
            "Number of true positive: 110\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 1\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 35\n",
            "============epoch 20 ================\n",
            "52/52 [==============================] - 24s 453ms/step - loss: 8.9354e-05 - accuracy: 0.1246\n",
            "52/52 [==============================] - 9s 170ms/step\n",
            "Outcome of training data of epoch 20:\n",
            "Number of true positive: 103\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 43\n",
            "============epoch 21 ================\n",
            "52/52 [==============================] - 24s 467ms/step - loss: 7.2443e-05 - accuracy: 0.0887\n",
            "52/52 [==============================] - 8s 165ms/step\n",
            "Outcome of training data of epoch 21:\n",
            "Number of true positive: 108\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 38\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 22 ================\n",
            "52/52 [==============================] - 24s 456ms/step - loss: 8.4855e-05 - accuracy: 0.1021\n",
            "52/52 [==============================] - 9s 171ms/step\n",
            "Outcome of training data of epoch 22:\n",
            "Number of true positive: 128\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 18\n",
            "============epoch 23 ================\n",
            "52/52 [==============================] - 24s 464ms/step - loss: 6.5054e-05 - accuracy: 0.0855\n",
            "52/52 [==============================] - 8s 166ms/step\n",
            "Outcome of training data of epoch 23:\n",
            "Number of true positive: 124\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 1\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 21\n",
            "============epoch 24 ================\n",
            "52/52 [==============================] - 24s 456ms/step - loss: 5.7904e-05 - accuracy: 0.0867\n",
            "52/52 [==============================] - 9s 168ms/step\n",
            "Outcome of training data of epoch 24:\n",
            "Number of true positive: 131\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 15\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 25 ================\n",
            "52/52 [==============================] - 25s 472ms/step - loss: 5.4256e-05 - accuracy: 0.0897\n",
            "52/52 [==============================] - 9s 170ms/step\n",
            "Outcome of training data of epoch 25:\n",
            "Number of true positive: 137\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 9\n",
            "============epoch 26 ================\n",
            "52/52 [==============================] - 24s 456ms/step - loss: 5.4597e-05 - accuracy: 0.0853\n",
            "52/52 [==============================] - 8s 164ms/step\n",
            "Outcome of training data of epoch 26:\n",
            "Number of true positive: 135\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 11\n",
            "============epoch 27 ================\n",
            "52/52 [==============================] - 24s 453ms/step - loss: 5.8203e-05 - accuracy: 0.0921\n",
            "52/52 [==============================] - 9s 168ms/step\n",
            "Outcome of training data of epoch 27:\n",
            "Number of true positive: 128\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 18\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "============epoch 28 ================\n",
            "52/52 [==============================] - 23s 445ms/step - loss: 4.9078e-05 - accuracy: 0.0858\n",
            "52/52 [==============================] - 8s 163ms/step\n",
            "Outcome of training data of epoch 28:\n",
            "Number of true positive: 144\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 2\n",
            "============epoch 29 ================\n",
            "52/52 [==============================] - 24s 462ms/step - loss: 5.1970e-05 - accuracy: 0.0816\n",
            "52/52 [==============================] - 9s 167ms/step\n",
            "Outcome of training data of epoch 29:\n",
            "Number of true positive: 134\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 12\n",
            "============epoch 30 ================\n",
            "52/52 [==============================] - 24s 468ms/step - loss: 5.2893e-05 - accuracy: 0.0966\n",
            "52/52 [==============================] - 9s 168ms/step\n",
            "Outcome of training data of epoch 30:\n",
            "Number of true positive: 131\n",
            "Number of true negative: 10\n",
            "Number of false positive FP1: 0\n",
            "Number of false positive FP2: 0\n",
            "Number of false negative: 15\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "Saving weights......\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n",
            "Done......\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Accuracy Prediction"
      ],
      "metadata": {
        "id": "sEay4nIdKLfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 '/content/TrackNetv2/3_in_1_out/accuracy.py' --load_weights='/content/TrackNetv2/3_in_1_out/model_33' --dataDir='/content/drive/MyDrive/npy' --tol=4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-gIIvJu8NiH",
        "outputId": "97bfdbd9-b296-4f3d-854f-efed8d5d5a39"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-14 23:36:44.692323: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-14 23:36:45.620814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-14 23:36:45.620925: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-12-14 23:36:45.620944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-12-14 23:36:48.733506: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Beginning evaluating......\n",
            "==========================================================\n",
            "2022-12-14 23:36:51.323216: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 828112896 exceeds 10% of free system memory.\n",
            "156/156 [==============================] - 13s 51ms/step\n",
            "Finish evaluating data1:(TP, TN, FP1, FP2, FN)=(134, 7, 1, 3, 11)\n",
            "==========================================================\n",
            "Number of true positive: 134\n",
            "Number of true negative: 7\n",
            "Number of false positive FP1: 1\n",
            "Number of false positive FP2: 3\n",
            "Number of false negative: 11\n",
            "accuracy: 0.9038461538461539\n",
            "precision: 0.9710144927536232\n",
            "recall: 0.9241379310344827\n",
            "Done......\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Test Data"
      ],
      "metadata": {
        "id": "DYRn55pQKPlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import getopt\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import piexif\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from TrackNet import TrackNet\n",
        "import keras.backend as K\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "import time\n",
        "BATCH_SIZE=1\n",
        "HEIGHT=288\n",
        "WIDTH=512\n",
        "sigma=2.5\n",
        "mag=1\n",
        "\n",
        "def genHeatMap(w, h, cx, cy, r, mag):\n",
        "\tif cx < 0 or cy < 0:\n",
        "\t\treturn np.zeros((h, w))\n",
        "\tx, y = np.meshgrid(np.linspace(1, w, w), np.linspace(1, h, h))\n",
        "\theatmap = ((y - (cy + 1))**2) + ((x - (cx + 1))**2)\n",
        "\theatmap[heatmap <= r**2] = 1\n",
        "\theatmap[heatmap > r**2] = 0\n",
        "\treturn heatmap*mag\n",
        "\n",
        "#time: in milliseconds\n",
        "def custom_time(time):\n",
        "\tremain = int(time / 1000)\n",
        "\tms = (time / 1000) - remain\n",
        "\ts = remain % 60\n",
        "\ts += ms\n",
        "\tremain = int(remain / 60)\n",
        "\tm = remain % 60\n",
        "\tremain = int(remain / 60)\n",
        "\th = remain\n",
        "\t#Generate custom time string\n",
        "\tcts = ''\n",
        "\tif len(str(h)) >= 2:\n",
        "\t\tcts += str(h)\n",
        "\telse:\n",
        "\t\tfor i in range(2 - len(str(h))):\n",
        "\t\t\tcts += '0'\n",
        "\t\tcts += str(h)\n",
        "\t\n",
        "\tcts += ':'\n",
        "\n",
        "\tif len(str(m)) >= 2:\n",
        "\t\tcts += str(m)\n",
        "\telse:\n",
        "\t\tfor i in range(2 - len(str(m))):\n",
        "\t\t\tcts += '0'\n",
        "\t\tcts += str(m)\n",
        "\n",
        "\tcts += ':'\n",
        "\n",
        "\tif len(str(int(s))) == 1:\n",
        "\t\tcts += '0'\n",
        "\tcts += str(s)\n",
        "\n",
        "\treturn cts\n",
        "\n",
        "\n",
        "try:\n",
        "\t(opts, args) = getopt.getopt(sys.argv[1:], '', [\n",
        "\t\t'video_name=',\n",
        "\t\t'load_weights='\n",
        "\t])\n",
        "\tif len(opts) != 2:\n",
        "\t\traise ''\n",
        "except:\n",
        "\tprint('usage: python3 predict.py --video_name=<videoPath> --load_weights=<weightPath>')\n",
        "\texit(1)\n",
        "\n",
        "for (opt, arg) in opts:\n",
        "\tif opt == '--video_name':\n",
        "\t\tvideoName = arg\n",
        "\telif opt == '--load_weights':\n",
        "\t\tload_weights = arg\n",
        "\telse:\n",
        "\t\tprint('usage: python3 predict.py --video_name=<videoPath> --load_weights=<weightPath>')\n",
        "\t\texit(1)\n",
        "\n",
        "#Loss function\n",
        "def custom_loss(y_true, y_pred):\n",
        "\tloss = (-1)*(K.square(1 - y_pred) * y_true * K.log(K.clip(y_pred, K.epsilon(), 1)) + K.square(y_pred) * (1 - y_true) * K.log(K.clip(1 - y_pred, K.epsilon(), 1)))\n",
        "\treturn K.mean(loss)\n",
        "\n",
        "model = load_model(load_weights, custom_objects={'custom_loss':custom_loss})\n",
        "\n",
        "print('Beginning predicting......')\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "f = open(videoName[:-4]+'_predict.csv', 'w')\n",
        "f.write('Frame,Visibility,X,Y,Time\\n')\n",
        "\n",
        "cap = cv2.VideoCapture(videoName)\n",
        "\n",
        "success, image1 = cap.read()\n",
        "success, image2 = cap.read()\n",
        "success, image3 = cap.read()\n",
        "\n",
        "ratio = image1.shape[0] / HEIGHT\n",
        "\n",
        "size = (int(WIDTH*ratio), int(HEIGHT*ratio))\n",
        "fps = 30\n",
        "\n",
        "if videoName[-3:] == 'avi':\n",
        "\tfourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "elif videoName[-3:] == 'mp4':\n",
        "\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "else:\n",
        "\tprint('usage: video type can only be .avi or .mp4')\n",
        "\texit(1)\n",
        "\n",
        "out = cv2.VideoWriter(videoName[:-4]+'_predict'+videoName[-4:], fourcc, fps, size)\n",
        "\n",
        "out.write(image1)\n",
        "out.write(image2)\n",
        "\n",
        "count = 2\n",
        "\n",
        "while success:\n",
        "\tunit = []\n",
        "\t#Adjust BGR format (cv2) to RGB format (PIL)\n",
        "\tx1 = image1[...,::-1]\n",
        "\tx2 = image2[...,::-1]\n",
        "\tx3 = image3[...,::-1]\n",
        "\t#Convert np arrays to PIL images\n",
        "\tx1 = array_to_img(x1)\n",
        "\tx2 = array_to_img(x2)\n",
        "\tx3 = array_to_img(x3)\n",
        "\t#Resize the images\n",
        "\tx1 = x1.resize(size = (WIDTH, HEIGHT))\n",
        "\tx2 = x2.resize(size = (WIDTH, HEIGHT))\n",
        "\tx3 = x3.resize(size = (WIDTH, HEIGHT))\n",
        "\t#Convert images to np arrays and adjust to channels first\n",
        "\tx1 = np.moveaxis(img_to_array(x1), -1, 0)\t\t\n",
        "\tx2 = np.moveaxis(img_to_array(x2), -1, 0)\t\t\n",
        "\tx3 = np.moveaxis(img_to_array(x3), -1, 0)\n",
        "\t#Create data\n",
        "\tunit.append(x1[0])\n",
        "\tunit.append(x1[1])\n",
        "\tunit.append(x1[2])\n",
        "\tunit.append(x2[0])\n",
        "\tunit.append(x2[1])\n",
        "\tunit.append(x2[2])\n",
        "\tunit.append(x3[0])\n",
        "\tunit.append(x3[1])\n",
        "\tunit.append(x3[2])\n",
        "\tunit=np.asarray(unit)\t\n",
        "\tunit = unit.reshape((1, 9, HEIGHT, WIDTH))\n",
        "\tunit = unit.astype('float32')\n",
        "\tunit /= 255\n",
        "\ty_pred = model.predict(unit, batch_size=BATCH_SIZE)\n",
        "\ty_pred = y_pred > 0.5\n",
        "\ty_pred = y_pred.astype('float32')\n",
        "\th_pred = y_pred[0]*255\n",
        "\th_pred = h_pred.astype('uint8')\n",
        "\tframe_time = custom_time(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
        "\tif np.amax(h_pred) <= 0:\n",
        "\t\tf.write(str(count)+',0,0,0,'+frame_time+'\\n')\n",
        "\t\tout.write(image3)\n",
        "\telse:\t\n",
        "\t\t#h_pred\n",
        "\t\t(cnts, _) = cv2.findContours(h_pred.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\t\trects = [cv2.boundingRect(ctr) for ctr in cnts]\n",
        "\t\tmax_area_idx = 0\n",
        "\t\tmax_area = rects[max_area_idx][2] * rects[max_area_idx][3]\n",
        "\t\tfor i in range(len(rects)):\n",
        "\t\t\tarea = rects[i][2] * rects[i][3]\n",
        "\t\t\tif area > max_area:\n",
        "\t\t\t\tmax_area_idx = i\n",
        "\t\t\t\tmax_area = area\n",
        "\t\ttarget = rects[max_area_idx]\n",
        "\t\t(cx_pred, cy_pred) = (int(ratio*(target[0] + target[2] / 2)), int(ratio*(target[1] + target[3] / 2)))\n",
        "\n",
        "\t\tf.write(str(count)+',1,'+str(cx_pred)+','+str(cy_pred)+','+frame_time+'\\n')\n",
        "\t\timage3_cp = np.copy(image3)\n",
        "\t\tcv2.circle(image3_cp, (cx_pred, cy_pred), 5, (0,0,255), -1)\n",
        "\t\tout.write(image3_cp)\n",
        "\timage1 = image2\n",
        "\timage2 = image3\n",
        "\tsuccess, image3 = cap.read()\n",
        "\tcount += 1\n",
        "\n",
        "f.close()\n",
        "out.release()\n",
        "end = time.time()\n",
        "print('Prediction time:', end-start, 'secs')\n",
        "print('Done......')"
      ],
      "metadata": {
        "id": "tQemp2_jKVw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 '/content/TrackNetv2/3_in_1_out/predict.py'  --save_weights_path='/content/TrackNetv2/3_in_1_out/model_33' --input_video_path='/content/drive/MyDrive/Recording #4.mp4' --output_video_path=\"/content/drive/MyDrive/tracked.mp4\" --n_classes=256"
      ],
      "metadata": {
        "id": "pSuRZ2A4K9d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ee-TCZHtLGwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3GgwgW8vK8tV"
      }
    }
  ]
}